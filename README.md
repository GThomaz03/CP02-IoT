# ğŸ§  Checkpoint 2 â€“ Redes Neurais com Keras

Disciplina: **Disruptive Architectures: IoT, IoB e Generative AI**  
Atividade: **Treinamento de Redes Neurais com Keras (Dados Tabulares)**  
Peso: **40% da nota do CP2**  

---

## ğŸ“‚ Estrutura do RepositÃ³rio

```
/redes-neurais-keras
â”‚â”€â”€ CP02-1.ipynb # ClassificaÃ§Ã£o Multiclasse (Wine Dataset)
â”‚â”€â”€ CP02-2.ipynb # RegressÃ£o (California Housing)
â”‚â”€â”€ teachable-machine-1
â”‚â”€â”€ teachable-machine-2
â”‚â”€â”€ README.md # InstruÃ§Ãµes e resultados
```


---

## ğŸ“Œ ExercÃ­cio 1 â€“ ClassificaÃ§Ã£o Multiclasse
- **Dataset**: [Wine Dataset (UCI)](https://archive.ics.uci.edu/dataset/109/wine) â€“ carregado via `sklearn.datasets.load_wine`.
- **Rede Neural (Keras)**:
  - 2 camadas ocultas (32 neurÃ´nios cada), ativaÃ§Ã£o **ReLU**
  - Camada de saÃ­da com 3 neurÃ´nios (softmax)
  - FunÃ§Ã£o de perda: `categorical_crossentropy`
  - Otimizador: `Adam`
- **ComparaÃ§Ã£o**:
  - `LogisticRegression`
  - `RandomForestClassifier`
- **MÃ©trica**: AcurÃ¡cia

---

## ğŸ“Œ ExercÃ­cio 2 â€“ RegressÃ£o
- **Dataset**: [California Housing Dataset](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset) â€“ carregado via `sklearn.datasets.fetch_california_housing`.
- **Rede Neural (Keras)**:
  - 3 camadas ocultas (64, 32, 16 neurÃ´nios), ativaÃ§Ã£o **ReLU**
  - SaÃ­da com 1 neurÃ´nio (linear)
  - FunÃ§Ã£o de perda: `mse`
  - Otimizador: `Adam`
- **ComparaÃ§Ã£o**:
  - `LinearRegression`
  - `RandomForestRegressor`
- **MÃ©tricas**: RMSE e MAE

---

## â–¶ï¸ Como Executar os Experimentos

### 1. Clonar o repositÃ³rio
```bash
git clone https://github.com/GThomaz03/CP02-IoT.git
cd CP02-IoT
```
### 2. Criar ambiente virtual (opcional, mas recomendado)
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```
### 3. Instalar dependÃªncias
```bash
pip install tensorflow scikit-learn pandas numpy matplotlib
```
### 4. Abrir os notebooks
```bash
jupyter notebook
```

E executar:
- exercicio1_classificacao.ipynb
- exercicio2_regressao.ipynb

---
ğŸ“Š Resultados Esperados

- ExercÃ­cio 1 (Wine Dataset):
    Comparar a acurÃ¡cia da rede neural com Logistic Regression e Random Forest.
        Normalmente, Random Forest tende a se sair melhor em datasets tabulares pequenos.

- ExercÃ­cio 2 (California Housing):
    Comparar RMSE/MAE entre rede neural, Linear Regression e Random Forest.
        Em geral, Random Forest atinge melhor desempenho, enquanto a rede neural precisa de mais ajustes de hiperparÃ¢metros.

---

ğŸ“Œ ConclusÃ£o

- Random Forest geralmente apresenta maior robustez em dados tabulares.
- Redes neurais podem alcanÃ§ar desempenho competitivo, mas sÃ£o mais sensÃ­veis a hiperparÃ¢metros.
- Linear Regression serve como baseline simples para comparaÃ§Ã£o.

---
Integarntes:

- Gabriel Alves Thomaz - RM558637

---
# Parte 2

links dos datasets:
- https://app.roboflow.com/teste-atffo/coco128-iugjx-c5qje/browse?queryText=&pageSize=50&startingIndex=0&browseQuery=true
- https://universe.roboflow.com/new-workspace-s0sid/bus-yqkys/dataset/2
- https://universe.roboflow.com/yu-cttti/motorcycle-a1sts/dataset/2

---
Teachable machine foi treinado com duas classes, Ã´nibus e motos utilizando os datasest citados acima e testado comuma imagem que nÃ£o foi utilizada no treinamento 
